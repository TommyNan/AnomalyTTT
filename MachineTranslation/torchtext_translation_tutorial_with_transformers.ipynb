{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "torchtext_translation_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TommyNan/AnomalyTTT/blob/master/MachineTranslation/torchtext_translation_tutorial_with_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w40yexyC0OKu"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXdXe_OiCdWu",
        "outputId": "d3a12be4-97ca-4c9c-b7dc-310f89475fc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!python -m pip install torchtext==0.6.0\n",
        "!python -m pip install einops"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.32.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (0.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torchtext==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchtext==0.6.0) (3.0.3)\n",
            "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "Installing collected packages: torchtext\n",
            "Successfully installed torchtext-0.6.0\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPHfPoKBVhNH"
      },
      "source": [
        "from einops import rearrange"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mxEZx8NBCS1",
        "outputId": "6b098a15-b61d-41c3-9532-a7b96c5c59a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m pip install spacy==2.3"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==2.3\n",
            "  Downloading spacy-2.3.0.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32minstalling build dependencies for spacy\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'spacy' when installing build dependencies for spacy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hOubTntBJhG"
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download fr\n",
        "!python -m spacy download de"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwmZq0or0OKy"
      },
      "source": [
        "\n",
        "Language Translation with TorchText\n",
        "===================================\n",
        "\n",
        "This tutorial shows how to use several convenience classes of ``torchtext`` to preprocess\n",
        "data from a well-known dataset containing sentences in both English and German and use it to\n",
        "train a sequence-to-sequence model with attention that can translate German sentences\n",
        "into English.\n",
        "\n",
        "- [Link to Original PyTorch Tutorial](https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html?highlight=transformer)\n",
        "- [Link to Andrew Peng's language translation implementation](https://github.com/andrewpeng02/transformer-translation)\n",
        "- [Interesting info about sorting sentences](https://towardsdatascience.com/understanding-transformers-the-programming-way-f8ed22d112b2)\n",
        "\n",
        "It is based off of\n",
        "`this tutorial <https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb>`__\n",
        "from PyTorch community member `Ben Trevett <https://github.com/bentrevett>`__\n",
        "and was created by `Seth Weidman <https://github.com/SethHWeidman/>`__ with Ben's permission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGgLWgQT0OKz"
      },
      "source": [
        "## Dataset\n",
        "----------------\n",
        "In this tutorial we'll use the `Multi30k dataset <https://github.com/multi30k/dataset>`__, which contains about 30,000 sentences (averaging about 13 words in length) in both English and German."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrjjUIpfBi_e",
        "outputId": "4a033870-5e20-4525-d68b-87fcbc03859f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import spacy\n",
        "import torchtext\n",
        "from torchtext.data import Field, BucketIterator"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchtext'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-786667537.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVjBGHWz0OKz"
      },
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "SRC = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"de\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"en\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0qCZlaB0OK2"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XCxlPKSoc7r"
      },
      "source": [
        "## What does our data look like?\n",
        "Torchtext preprocesses our data to give us a mapping from our source language to the target language and back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4_tYFC4DnpY"
      },
      "source": [
        "# Printing a list of tokens mapping integer to strings\n",
        "print(SRC.vocab.itos)\n",
        "# Printing a dict mapping tokens to indices\n",
        "print(SRC.vocab.stoi)\n",
        "# Printing the index of an actual word\n",
        "print(SRC.vocab.stoi['ein'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gLC73JK0OK5"
      },
      "source": [
        "``BucketIterator``\n",
        "----------------\n",
        "The last ``torchtext`` specific feature we'll use is the ``BucketIterator``,\n",
        "which is easy to use since it takes a ``TranslationDataset`` as its\n",
        "first argument. Specifically, as the docs say:\n",
        "Defines an iterator that batches examples of similar lengths together.\n",
        "Minimizes amount of padding needed while producing freshly shuffled\n",
        "batches for each new epoch. See pool for the bucketing procedure used.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJXdis5w0OK6"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJwrYvke0OK9"
      },
      "source": [
        "Defining our ``nn.Module`` and ``Optimizer``\n",
        "----------------\n",
        "We define our ``nn.Module`` using the nn.Transformer module implemented in PyTorch.\n",
        "In order to use the Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1L2qQrk0OK-"
      },
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "import math\n",
        "\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "# Source: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.src_embedding = nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "        self.tgt_embedding = nn.Embedding(INPUT_DIM, ENC_EMB_DIM)\n",
        "        self.transformer = nn.Transformer(nhead=8, num_encoder_layers=2, d_model=ENC_EMB_DIM)\n",
        "        self.linear = nn.Linear(ENC_EMB_DIM, OUTPUT_DIM)\n",
        "        pos_dropout = 0.1\n",
        "        max_seq_length = 128\n",
        "        self.pos_enc = PositionalEncoding(ENC_EMB_DIM, pos_dropout, max_seq_length)\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.5, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None, tgt_mask=None):\n",
        "        # TODO: Investigate masks, positional encoding, understand Rearrange(), debug model output (output has negative numbers for some reason)\n",
        "        # Original src shape: (sentence length=24?, batch_size=128)\n",
        "        # Original tgt shape: (sentence length=24?, batch_size=128)\n",
        "        # Transformer expects: (sentence length=24, batch_size=128, embedding_size=128)\n",
        "        src_emb = self.pos_enc(self.src_embedding(src) * math.sqrt(ENC_EMB_DIM))\n",
        "        tgt_emb = self.pos_enc(self.tgt_embedding(tgt) * math.sqrt(ENC_EMB_DIM))\n",
        "        out = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "model = TransformerModel().to(device)\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_normal_(p)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98))\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUzRIoUd0OLC"
      },
      "source": [
        "Note: when scoring the performance of a language translation model in\n",
        "particular, we have to tell the ``nn.CrossEntropyLoss`` function to\n",
        "ignore the indices where the target is simply padding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aYGQRq70OLC"
      },
      "source": [
        "# Checking index of special tokens\n",
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "SOS_IDX = TRG.vocab.stoi['<sos>']\n",
        "EOS_IDX = TRG.vocab.stoi['<eos>']\n",
        "UNK_IDX = TRG.vocab.stoi['<unk>']\n",
        "print('pad index:', PAD_IDX)\n",
        "print('sos index:', SOS_IDX)\n",
        "print('eos index:', EOS_IDX)\n",
        "print('unk index:', UNK_IDX)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7FKKikF0OLF"
      },
      "source": [
        "## Training and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE8O8EKjV7Iw"
      },
      "source": [
        "def gen_nopeek_mask(length):\n",
        "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h')\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uevv7ldzjat4"
      },
      "source": [
        "def example_translate(model, example_sentence_src):\n",
        "    # Translate example sentence\n",
        "    example_tensor_src = string_to_indices(SRC, example_sentence_src).view(-1, 1)\n",
        "    example_sentence_tgt = '<sos>'\n",
        "    example_tensor_tgt = string_to_indices(TRG, example_sentence_tgt).view(-1, 1)\n",
        "    src = example_tensor_src.to(device)\n",
        "    tgt = example_tensor_tgt.to(device)\n",
        "\n",
        "    print('----------Translating--------------')\n",
        "    for i in range(128):\n",
        "        print('Src:', src)\n",
        "        print('Tgt:', tgt)\n",
        "        src_key_padding_mask = src == PAD_IDX\n",
        "        tgt_key_padding_mask = tgt == PAD_IDX\n",
        "        memory_key_padding_mask = src_key_padding_mask.clone()\n",
        "        src_key_padding_mask = rearrange(src_key_padding_mask, 'n s -> s n')\n",
        "        tgt_key_padding_mask = rearrange(tgt_key_padding_mask, 'n s -> s n')\n",
        "        memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "        tgt_mask = gen_nopeek_mask(tgt.shape[0]).to('cuda')\n",
        "        print('Tgt mask:', tgt_mask)\n",
        "\n",
        "        output = model(src, tgt, 0, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_mask=tgt_mask) #turn off teacher forcing\n",
        "\n",
        "        print('Output:', output)\n",
        "        # TODO: Check that the argmax line is correct\n",
        "        output_index = torch.argmax(output, dim=2)[-1].item()\n",
        "        output_word = TRG.vocab.itos[output_index]\n",
        "        example_sentence_tgt = example_sentence_tgt + ' ' + output_word\n",
        "        print('Translated sentence so far:', example_sentence_tgt)\n",
        "        example_tensor_tgt = string_to_indices(TRG, example_sentence_tgt).view(-1, 1)\n",
        "        tgt = example_tensor_tgt.to(device)\n",
        "        if output_word == '<eos>':\n",
        "            break\n",
        "    print('-----------Finished Translating--------------')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNfqdy9B0OLG"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def indices_to_string(LANGUAGE, batch):\n",
        "    words_list = []\n",
        "    for sentence in batch.transpose(1, 0):\n",
        "        sentence_list = sentence.tolist()\n",
        "        words = []\n",
        "        for index in sentence_list:\n",
        "            word = LANGUAGE.vocab.itos[index]\n",
        "            words.append(word)\n",
        "        words_list.append(words)\n",
        "    return words_list\n",
        "\n",
        "def string_to_indices(LANGUAGE, sentence):\n",
        "    words = sentence.split()\n",
        "    indices = []\n",
        "    for word in words:\n",
        "        if word in LANGUAGE.vocab.stoi:\n",
        "            index = LANGUAGE.vocab.stoi[word]\n",
        "            indices.append(index)\n",
        "        else:\n",
        "            index = LANGUAGE.vocab.stoi['<unk>']\n",
        "            indices.append(index)\n",
        "    result = torch.tensor(indices)\n",
        "    return result\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: BucketIterator,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.src\n",
        "        tgt = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Original src shape: (sentence length=24, batch_size=128)\n",
        "        # Transformer expects: (sentence length=24, batch_size=128, embedding_size=128)\n",
        "        src_key_padding_mask = src == PAD_IDX\n",
        "        tgt_key_padding_mask = tgt == PAD_IDX\n",
        "        memory_key_padding_mask = src_key_padding_mask.clone()\n",
        "        src_key_padding_mask = rearrange(src_key_padding_mask, 'n s -> s n')\n",
        "        tgt_key_padding_mask = rearrange(tgt_key_padding_mask, 'n s -> s n')\n",
        "        memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "        tgt_sentence_len = tgt.shape[0] - torch.sum(tgt_key_padding_mask, axis=1)\n",
        "        tgt_inp, tgt_out = tgt[:-1, :], tgt[1:, :]\n",
        "        tgt_key_padding_mask = tgt_key_padding_mask[:, :-1]\n",
        "        tgt_mask = gen_nopeek_mask(tgt_inp.shape[0]).to('cuda')\n",
        "        output = model(src, tgt_inp, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_mask=tgt_mask)\n",
        "        from_one_hot = torch.argmax(output, dim=2)\n",
        "        # output shape: (sentence length=24, batch_size=128, vocab=5893)\n",
        "        # Original tgt shape: (sentence length=24, batch_size=128)\n",
        "\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        tgt_out = tgt_out.view(-1)\n",
        "\n",
        "        loss = criterion(output, tgt_out)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: BucketIterator,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    print('Evaluating')\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            tgt = batch.trg\n",
        "\n",
        "            src_key_padding_mask = src == PAD_IDX\n",
        "            tgt_key_padding_mask = tgt == PAD_IDX\n",
        "            memory_key_padding_mask = src_key_padding_mask.clone()\n",
        "            src_key_padding_mask = rearrange(src_key_padding_mask, 'n s -> s n')\n",
        "            tgt_key_padding_mask = rearrange(tgt_key_padding_mask, 'n s -> s n')\n",
        "            memory_key_padding_mask = rearrange(memory_key_padding_mask, 'n s -> s n')\n",
        "            tgt_mask = gen_nopeek_mask(tgt.shape[0]).to('cuda')\n",
        "            output = model(src, tgt, 0, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=memory_key_padding_mask, tgt_mask=tgt_mask) #turn off teacher forcing\n",
        "            from_one_hot = torch.argmax(output, dim=2)\n",
        "            #print(src.shape, output.shape, from_one_hot.shape, tgt.shape)\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            #print('Src:', src.transpose(1, 0))\n",
        "            #print('Predicted:', from_one_hot.transpose(1, 0))\n",
        "            #print('Target:', tgt.transpose(1, 0))\n",
        "            src_words = indices_to_string(SRC, src)\n",
        "            predicted_words = indices_to_string(TRG, from_one_hot)\n",
        "            tgt_words = indices_to_string(TRG, tgt)\n",
        "            #for i, src in enumerate(src_words):\n",
        "            #    print('----------------------------------')\n",
        "            #    print(' '.join(src))\n",
        "            #    print(' '.join(predicted_words[i]))\n",
        "            #    print(' '.join(tgt_words[i]))\n",
        "\n",
        "            tgt = tgt[1:].view(-1)\n",
        "            loss = criterion(output, tgt)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BL7yqmWYyMs"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YUFxU6DX6gR"
      },
      "source": [
        "test_loss = evaluate(model, test_iterator, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Mt6ju0mhL2"
      },
      "source": [
        "example_sentence_src = '<sos> der himmel ist blau <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'\n",
        "#example_sentence_src = '<sos> viele menschen haben sich versammelt , um etwas zu sehen , das nicht auf dem foto ist . <eos> <pad> <pad> <pad> <pad>'\n",
        "example_translate(model, example_sentence_src)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}